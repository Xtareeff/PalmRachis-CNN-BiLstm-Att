# Palm Rachis-wise CNN-BiLSTM with Attention for Disease Classification

# Overview

This project presents a deep learning model for Palm Leaf Disease Classification using a CNN BiLSTM architecture with an Attention mechanism. T

**Key Features:**
*   **Hybrid Architecture:** Combines a ResNet18 network for feature extraction, a BiLSTM network for sequence processing, and an Attention mechanism for decision interpretability.
*   **Sequential Processing:** The feature map generated by the CNN is transformed into a sequence representing vertical steps along the rachis by averaging across the width.
*   **Explainable AI (XAI):** Provides both **Grad-CAM** and **Attention Timeline** visualizations to interpret the model's predictions.

## Project Structure

| File | Description |
| :--- | :--- |
| `main.py` | The main entry point of the program. It contains the configuration settings and executes the training, evaluation, and XAI reporting stages. |
| `preprocessing.py` | Contains utility functions for data processing, including stratified splitting and creating `DataLoader` objects from an `ImageFolder` dataset. |
| `model.py` | Contains the definition of the `PalmRachis_BiLSTM_Attn` model, as well as the training (`train_model`) and evaluation (`evaluate`) functions, which include plotting training curves, Confusion Matrix, and ROC curves. |
| `xai.py` | Contains the functions responsible for generating Explainable AI (XAI) reports, including **Grad-CAM** and the **Attention Timeline** along the rachis. |
| `requirements.txt` | A list of all required libraries and dependencies for running the project. |

## Requirements and Dependencies

To run this project, you need to install the dependencies listed in the `requirements.txt` file.

```bash
pip install -r requirements.txt
```

**Note:** The project requires the `opencv-python` library (`cv2`) for some image processing operations in the XAI part.

## Data Setup

The code use online dataset "https://data.mendeley.com/datasets/g684ghfxvg/2" , the code assumes the dataset is organized in the standard PyTorch `ImageFolder` format, where images are categorized into subfolders named after their classes.

```
/path/to/data/
├── Class_A/
│   ├── img1.jpg
│   └── img2.jpg
├── Class_B/
│   ├── img3.jpg
│   └── img4.jpg
└── ...
```

**Updating Data Path:**
Make sure to update the `DATA_DIR` variable in the `CFG` class inside `main.py` to point to the correct path of your dataset.

```python
# main.py
@dataclass
class CFG:
    DATA_DIR: str = "../input/pam-leaf-dataa/Processed"  # <-- Update this path
    OUT_DIR:  str = "./palm_rachis_out"
    # ...
```

## Usage

To run the training, evaluation, and XAI report generation process, execute the `main.py` file:

```bash
python main.py
```

## Outputs

All outputs and results will be saved in the directory specified by `OUT_DIR` (default: `./palm_rachis_out/run_rachis_attn/`).

**Key Output Files and Folders:**
*   `best_model.pth`: The best model weights based on validation accuracy.
*   `train_log.csv`: A training log containing loss and accuracy for each epoch.
*   `train_val_curves_true.png`: A plot showing the training and validation loss/accuracy curves.
*   `confusion_matrix.png`: The confusion matrix from the evaluation results.
*   `roc_multiclass.png`: Multiclass ROC curves.
*   `xai/`: A folder containing XAI panels for selected samples, including Grad-CAM overlays and Attention Timeline plots.

## Explainable AI (XAI)

The model uses two main mechanisms for explanation:

1.  **Attention Timeline:**
    *   Attention weights are calculated along the sequence (rachis from base to tip).
    *   The **Attention Timeline** plot indicates which parts of the rachis the model focused on most to make its decision.

2.  **Grad-CAM:**
    *   A heatmap is generated to visualize the regions in the image that contributed most significantly to the model's final prediction.
    *   These heatmaps are saved as overlays on the original images in the `xai/` folder.

---
**Author:** A.T
**Date:** October 2025
